{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Amazon Web Scraping.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyNMyz9WFDGx7qSOeAz8xWCG"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"49rrIYjcpFop"},"source":[""]},{"cell_type":"code","metadata":{"id":"5RXOcneoktBH","executionInfo":{"status":"ok","timestamp":1632297044166,"user_tz":-330,"elapsed":32613,"user":{"displayName":"Khushboo Agarwal","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh-gkrCK9mc7D-R8eWUBsK32Ze_lwR43Rkn8b830Q=s64","userId":"13806457027185649152"}}},"source":["# importing libraries \n","from bs4 import BeautifulSoup \n","import requests \n","import csv\n","\n","def scrap(URL): \n","    # specifying user agent, You can use other user agents \n","    # available on the internet \n","    HEADERS = ({'User-Agent': \n","                'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko)Chrome/44.0.2403.157 Safari/537.36', \n","                                'Accept-Language': 'en-US, en;q=0.5'}) \n","    # Making the HTTP Request \n","    webpage = requests.get(URL, headers=HEADERS) \n","\n","    # Creating the Soup Object containing all data \n","    soup = BeautifulSoup(webpage.content, \"html.parser\") \n","    records=[]\n","    results=soup.find_all('div',attrs={'data-component-type':'s-search-result'})\n","    \n","    for item in results :\n","      record = extract_record(item)\n","      if record:\n","        records.append(record)\n","    return records\n","\n","def extract_record(item):\n","\n","   # retreiving product title \n","    try: \n","      title = item.find(\"span\",attrs={\"class\": 'a-size-medium a-color-base a-text-normal'}) \n","      title = title.string.strip().replace(',', '') \n","     \n","    except AttributeError: \n","      title = \"NA\"\n","   # retreiving price \n","    try: \n","        price = item.find(\"span\", attrs={'class': 'a-offscreen'})\n","        price=price.string.strip().replace(',', '') \n","   \n","    except AttributeError: \n","        price = \"NA\"\n","    # retreiving product rating \n","    try: \n","        rating = item.find(\"span\", attrs={'class': 'a-icon-alt'})\n","        rating=rating.string.strip().replace(',', '') \n","\n","    except: \n","         rating = \"NA\"\n","   \n","    #retrieving review count\n","    try: \n","        review_count = item.find(\"span\", attrs={'class': 'a-size-base'})\n","        review_count=review_count.text \n","\n","    except AttributeError: \n","        review_count = \"NA\"\n","  \n","    # retrieve delivery status \n","    try: \n","        delivery = item.find(\"span\", attrs={'aria-label': 'FREE Delivery by Amazon'}) \n","        delivery = delivery.find(\"span\").string.strip().replace(',', '') \n","\n","    except AttributeError: \n","        delivery = \"No free delivery\"\n","    \n","    result=(title,price,rating,review_count,delivery)\n","    return result\n","    \n","results=[]\n","for page in range(1,21):\n","  url='https://www.amazon.in/s?k=shoes&i=shoes&rh=n%3A1983518031%2Cp_36%3A100000-250000&dc&page={}&qid=1631962645&rnid=4516629031&ref=sr_nr_p_36_1'.format(page)\n","  records=scrap(url)\n","  results=results+records\n","with open(\"data.csv\", \"w\") as f:\n","      writer = csv.writer(f)\n","      writer.writerow(['Title','Price','Ratings','Review Count','Free Ship'])\n","      writer.writerows(results)"],"execution_count":1,"outputs":[]},{"cell_type":"code","metadata":{"id":"X8Sf3xMJvz87"},"source":[""],"execution_count":null,"outputs":[]}]}